{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import test_dp               # required for testing and grading your code\n",
    "import gridworld_mdp as gw   # defines the MDP for a 4x4 gridworld\n",
    "import numpy as np\n",
    "import pprint\n",
    "import sys\n",
    "if \"../\" not in sys.path:\n",
    "  sys.path.append(\"../\") \n",
    "from lib.envs.gridworld import GridworldEnv\n",
    "env = GridworldEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(state_count, gamma, theta, get_available_actions, get_transitions):\n",
    "    \n",
    "    def one_step_lookahead(state, V):\n",
    "        A = np.zeros(env.nA)\n",
    "        for a in range(env.nA):\n",
    "            for prob, next_state, reward, done in env.P[state][a]:\n",
    "                A[a] += prob * (reward + .9 * V[next_state])\n",
    "            \n",
    "        return A\n",
    "    \n",
    "    V = np.zeros(env.nS)                # init all state value estimates to 0\n",
    "    pi = state_count*[0]\n",
    "    \n",
    "    # init with a policy with first avail action for each state\n",
    "    for s in range(state_count):\n",
    "        avail_actions = get_available_actions(s)\n",
    "        pi[s] = avail_actions[0]\n",
    "    \n",
    "    while True:\n",
    "        # Stopping condition\n",
    "        delta = 0\n",
    "        # Update each state...\n",
    "        for s in range(state_count):\n",
    "            # Do a one-step lookahead to find the best action\n",
    "            A = one_step_lookahead(s, V)\n",
    "            best_action_value = np.max(A)\n",
    "            # Calculate delta across all states seen so far\n",
    "            delta = max(delta, np.abs(best_action_value - V[s]))\n",
    "            # Update the value function. Ref: Sutton book eq. 4.10. \n",
    "            V[s] = best_action_value        \n",
    "        # Check if we can stop \n",
    "        if delta < theta:\n",
    "            break\n",
    "    policy = np.zeros([env.nS, env.nA])\n",
    "    for s in range(env.nS):\n",
    "        # One step lookahead to find the best action for this state\n",
    "        A = one_step_lookahead(s, V)\n",
    "        best_action = np.argmax(A)\n",
    "        # Always take the best action\n",
    "        policy[s, best_action] = 1.0\n",
    "    dict={0:\"up\",1:\"right\",2:\"down\",3:\"left\"}\n",
    "    for i in range(len(policy)-1):\n",
    "        for j in range(4):\n",
    "            if(policy[i][j]==1.):\n",
    "                pi[i]=dict[j]\n",
    "    # insert code here to iterate using policy evaluation and policy improvement (see Policy Iteration algorithm)\n",
    "    return (V, pi)        # return both the final value function and the final policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values= [ 0.   -1.   -1.9  -2.71 -1.   -1.9  -2.71 -1.9  -1.9  -2.71 -1.9  -1.\n",
      " -2.71 -1.9  -1.    0.  ]\n",
      "Policy= ['up', 'left', 'left', 'down', 'up', 'up', 'up', 'down', 'up', 'up', 'right', 'down', 'up', 'right', 'right']\n"
     ]
    }
   ],
   "source": [
    "n_states = gw.get_state_count()\n",
    "\n",
    "# test our function\n",
    "values, policy = value_iteration(state_count=n_states, gamma=.9, theta=.001, get_available_actions=gw.get_available_actions, \\\n",
    "    get_transitions=gw.get_transitions)\n",
    "\n",
    "print(\"Values=\", values)\n",
    "print(\"Policy=\", policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output from running above cell:**\n",
    "\n",
    "`\n",
    "Values= [0.0, -1.0, -1.9, -2.71, -1.0, -1.9, -2.71, -1.9, -1.9, -2.71, -1.9, -1.0, -2.71, -1.9, -1.0]\n",
    "Policy= ['up', 'left', 'left', 'down', 'up', 'up', 'up', 'down', 'up', 'up', 'down', 'down', 'up', 'right', 'right']\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: Value Iteration\n",
      "passed test: return value is tuple\n",
      "passed test: length of tuple = 2\n",
      "passed test: v is list of length=15\n",
      "passed test: values of v elements\n",
      "passed test: pi is list of length=15\n",
      "passed test: values of pi elements\n",
      "PASSED: Value Iteration passcode = 9990-000\n"
     ]
    }
   ],
   "source": [
    "# test our function using the test_db helper\n",
    "test_dp.value_iteration_test( value_iteration ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
